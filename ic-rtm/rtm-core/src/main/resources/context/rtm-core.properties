
#
rtm.batch.head=tenant:system:flow:user:passwd
rtm.batch.head.properits=:
rtm.batch.head.message=char(3)
rtm.bsn.last.time=3600000
#hbase
zookeeper.quorum=BIU-DEV-BaaS-app1/kfk,BIU-DEV-BaaS-app2/kfk,BIU-DEV-BaaS-app3/kfk
hbase.client.port=49181

#hbase copy 
hbase.copy.tableName=batch_copy_
hbase.copy.columnFamilyName=batch_detail$batch_remark
hbase.output.tableName=RTM_OUTPUT_DETAIL_
#file-reader,dubbo-reader
rtm.record.split=record_split
rtm.field.split=field_split

#kafka name
rtm.kafka.name=bmckafka$amckafka
#kafka mds
metadata.broker.list=192.168.0.226:39181
#kafka fix
serializer.class=kafka.serializer.DefaultEncoder
key.serializer.class=kafka.serializer.StringEncoder
partitioner.class=com.ai.paas.ipaas.mds.impl.sender.ModPartitioner
request.required.acks=1
queue.buffering.max.messages=1048576
producer.type=sync
message.send.max.retries=3
compression.codec=none
request.timeout.ms=20000
batch.num.messages=64000
send.buffer.bytes=67108864
maxProducer=5
#serializer.class=kafka.serializer.StringEncoder
request.required.acks=1


#executor threadPool
ctp.rtm.executor.corePoolSize=20
ctp.rtm.executor.maxPoolSize=50
ctp.rtm.executor.keepAliveTime=1
ctp.rtm.executor.blockingQueueSize=100

#mysql batch
rtm.batch.log.name=RTM_BATCH_LOG_

database.name=mysql


#config hbase or mysql to store copies,0 is mysql ,1 is hbase
usedatabase=0

#mysql copy

mysql.copy.tableName=rtm_batch_copy_

mysql.output.tableName=rtm_output_detail_

